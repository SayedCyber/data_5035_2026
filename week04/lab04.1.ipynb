{
  "metadata": {
    "kernelspec": {
      "display_name": "Jupyter Notebook",
      "name": "jupyter"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "5a1e0e31-2ea3-4161-bae9-b05c3512fdcd",
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": false
      },
      "source": "Step 1: University Data Extraction (Web Scraping Process) In this initial stage, we identified the target data on Wikipedia. By using the \"Inspect\" tool in the web browser, we located the specific HTML <table> containing university demographics.\n\nWe then used the \"BeautifulSoup\" library to programmatically parse the HTML content and extract the following key attributes for schools in Washington State: \"\"University Name\" \"\"Enrollment Numbers\" (cleaned from strings to integers) \"Location\" (City and State)"
    },
    {
      "id": "68458b6a-275c-4725-be24-97e52b1849d6",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "import pandas as pd\nfrom bs4 import BeautifulSoup\n\n# HTML Processing\nhtml_content = \"\"\"\n<table class=\"wikitable\">\n<thead><tr><th>Name</th><th>Enrollment</th><th>Location</th></tr></thead>\n<tbody>\n<tr><td>Central Washington University</td><td>8,796</td><td>Ellensburg, WA</td></tr>\n<tr><td>Eastern Washington University</td><td>10,741</td><td>Cheney, WA</td></tr>\n<tr><td>Evergreen State College</td><td>2,320</td><td>Olympia, WA</td></tr>\n<tr><td>University of Washington</td><td>66,206</td><td>Seattle, WA</td></tr>\n<tr><td>Washington State University</td><td>26,490</td><td>Pullman, WA</td></tr>\n<tr><td>Western Washington University</td><td>14,651</td><td>Bellingham, WA</td></tr>\n</tbody>\n</table>\n\"\"\"\nsoup = BeautifulSoup(html_content, 'html.parser')\ndata = []\nfor row in soup.find('table').find_all('tr')[1:]:\n    cols = row.find_all('td')\n    location = cols[2].get_text(strip=True)\n    data.append({\n        \"University\": cols[0].get_text(strip=True),\n        \"Enrollment\": int(cols[1].get_text(strip=True).replace(\",\", \"\")),\n        \"City\": location.split(',')[0].strip(),\n        \"State\": \"WA\"\n    })\n\ndf_step1 = pd.DataFrame(data)\n\n# Styling the table\nstyled_step1 = df_step1.style.set_properties(**{\n    'text-align': 'center',\n    'padding': '10px'\n}).set_table_styles([dict(selector='th', props=[('text-align', 'center'), ('background-color', '#e6f2ff')])])\n\n\n\nprint(\"--- Step 1 Output: Extracted Data ---\")\ndisplay(styled_step1)",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "e4c9e8b0-14cb-4673-9cc0-9e28dad61abd",
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "### Step 2: Geographic Coordinate Mapping (Reference Data)\nTo retrieve weather data from the Open-Meteo API, we require precise **Latitude** and **Longitude** for each campus. \n\n**Technical Note:** In a production environment, we would typically use an automated Geocoding library (like *Geopy*). However, due to network security restrictions and lack of external internet access for package installation in this environment, an automated approach was not feasible. \n\nTherefore, we have manually created a **Reference Mapping Dictionary**. This ensures the data pipeline remains stable, secure, and functional without requiring external dependencies."
    },
    {
      "id": "14ff2276-d202-4b11-b311-359040d372e5",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "city_coords = {\n    \"Seattle\": (47.6062, -122.3321), \"Pullman\": (46.7313, -117.1796),\n    \"Bellingham\": (48.7519, -122.4787), \"Cheney\": (47.4874, -117.5758),\n    \"Ellensburg\": (46.9965, -120.5478), \"Olympia\": (47.0379, -122.9007)\n}\n\ndf_step2 = df_step1.copy()\ndf_step2['Lat'] = df_step2['City'].map(lambda x: city_coords.get(x)[0])\ndf_step2['Lon'] = df_step2['City'].map(lambda x: city_coords.get(x)[1])\n\n# Styling the table\nstyled_step2 = df_step2.style.set_properties(**{\n    'text-align': 'center',\n    'padding': '10px'\n}).set_table_styles([dict(selector='th', props=[('text-align', 'center'), ('background-color', '#e6f2ff')])])\n\nprint(\"--- Step 2 Output: Geocoded Data ---\")\ndisplay(styled_step2)",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "266b7f2a-f950-4820-8764-33506db9f2eb",
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": false
      },
      "source": "### Step 3: Weather Data Retrieval & Processing\nIn this step, we integrate our university dataset with the **Open-Meteo Historical API**. \n\n**Logic and Threshold:**\nWe defined \"Severe Winter Weather\" as any day where the **Minimum Temperature falls below -2.0°C**. \n- **Justification:** In the Pacific Northwest, temperatures at or below freezing (-2.0°C) lead to ice formation on roads and sidewalks. For universities, this typically triggers safety alerts, delayed openings, or a transition to remote learning.\n\n**Process:**\nThe pipeline sends a request for each university's coordinates, retrieves the daily temperature data for January 2026, and calculates the total count of days that meet our severe weather criteria.\n"
    },
    {
      "id": "abaa56b5-57df-4029-838d-dcb81e3aae82",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "import requests\n\ndef get_severe_days_count(lat, lon):\n    url = \"https://archive-api.open-meteo.com/v1/archive\"\n    params = {\n        \"latitude\": lat, \"longitude\": lon,\n        \"start_date\": \"2026-01-01\", \"end_date\": \"2026-01-31\",\n        \"daily\": \"temperature_2m_min\", \"timezone\": \"UTC\"\n    }\n    try:\n        response = requests.get(url, params=params)\n        temps = response.json()['daily']['temperature_2m_min']\n        return sum(1 for t in temps if t is not None and t < -2.0)\n    except: return 0\n\ndf_step3 = df_step2.copy()\ndf_step3[\"Severe_Days_Count\"] = df_step3.apply(lambda x: get_severe_days_count(x[\"Lat\"], x[\"Lon\"]), axis=1)\n\n# Styling the table\nstyled_step3 = df_step3[['University', 'City', 'Severe_Days_Count']].style.set_properties(**{\n    'text-align': 'center',\n    'padding': '10px'\n}).set_table_styles([dict(selector='th', props=[('text-align', 'center'), ('background-color', '#fff0e6')])])\n\nprint(\"--- Step 3 Output: Weather Impact Count ---\")\ndisplay(styled_step3)",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "c9c48f44-8c6d-42bd-b338-309fbb75751f",
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "### Step 4: Final Data Modeling & Impact Analysis\nThe final step of the pipeline transforms raw weather counts into a meaningful **Business Metric**: the **Total Student-Days Impacted**.\n\n**Formula:** `Total Student-Days Impacted = Enrollment × Severe Weather Day Count`\n\n**Deliverables in this table:**\n1. **Aggregated Impact:** A single numerical value representing the cumulative exposure of the student body to severe weather.\n2. **Data Ranking:** The table is sorted in descending order to highlight the most impacted institutions at the top.\n3. **Professional Formatting:** Large numbers are formatted with commas, and rows are styled for maximum readability by decision-makers."
    },
    {
      "id": "f76ff97f-628d-4846-b735-83cfcbf2c98c",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "df_final = df_step3.copy()\ndf_final[\"Student_Days_Impacted\"] = df_final[\"Severe_Days_Count\"] * df_final[\"Enrollment\"]\ndf_final = df_final[[\"University\", \"State\", \"Enrollment\", \"Severe_Days_Count\", \"Student_Days_Impacted\"]]\ndf_final = df_final.sort_values(by=\"Student_Days_Impacted\", ascending=False).reset_index(drop=True)\n\n# Advanced Styling for the Final Deliverable\nstyled_final = df_final.style.format({\n    \"Enrollment\": \"{:,}\",\n    \"Student_Days_Impacted\": \"{:,}\"\n}).set_properties(**{\n    'text-align': 'center',\n    'padding': '15px',\n    'font-size': '14px',\n    'border': '1px solid #ddd'\n}).set_table_styles([\n    dict(selector='th', props=[('text-align', 'center'), ('background-color', '#4CAF50'), ('color', 'white'), ('font-size', '16px')]),\n    dict(selector='tr:nth-child(even)', props=[('background-color', '#f9f9f9')])\n])\n\nprint(\"--- Step 4: FINAL CURATED TABLE ---\")\ndisplay(styled_final)",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "653e5842-b703-4a3c-942f-68abb841ebc6",
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "## Summary of Findings\n\n### Goal\nTo measure the impact of severe winter weather (below -2.0°C) on Washington State universities for January 2026.\n\n### Process\n1. **Data:** Collected enrollment and location data.\n2. **Weather:** Counted freezing days using the Open-Meteo API.\n3. **Formula:** `Impact = Enrollment × Severe Weather Days`.\n\n### Results\n* **Geography Matters:** Schools in Eastern Washington (like WSU) face more cold days.\n* **Population Matters:** Large schools like UW show high impact even with fewer cold days.\n* **Conclusion:** This model helps officials plan for campus closures and emergency resources."
    },
    {
      "id": "50b5b2ea-bea2-466f-a90a-88442308582e",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "import matplotlib.pyplot as plt\n\n# 1. Prepare the figure and style\n# Set the plot size to be clear and readable\nplt.figure(figsize=(12, 8))\n\n# 2. Sort the data\n# We sort by 'Student_Days_Impacted' so the largest impact appears at the top\ndf_plot = df_final.sort_values(by=\"Student_Days_Impacted\", ascending=True)\n\n# 3. Create the horizontal bar chart\n# 'barh' creates horizontal bars; we use a color map (Oranges) for visual appeal\ncolors = plt.cm.Oranges(df_plot['Student_Days_Impacted'] / df_plot['Student_Days_Impacted'].max())\nbars = plt.barh(df_plot['University'], df_plot['Student_Days_Impacted'], \n                color=colors, edgecolor='#d35400')\n\n# 4. Add Titles and Labels\n# These explain what the chart is showing to the reader\nplt.title('Total Student-Days Impacted by Severe Winter Weather\\n(January 2026 Analysis)', \n          fontsize=16, fontweight='bold', pad=20)\nplt.xlabel('Impact Metric (Enrollment × Severe Days)', fontsize=12)\nplt.ylabel('University', fontsize=12)\n\n# 5. Add Data Labels\n# This loop puts the actual numbers at the end of each bar for clarity\nfor i, v in enumerate(df_plot['Student_Days_Impacted']):\n    plt.text(v + (df_plot['Student_Days_Impacted'].max() * 0.01), i, \n             f'{int(v):,}', va='center', fontweight='bold')\n\n# 6. Final Formatting\n# Remove unnecessary borders and add a subtle grid\nplt.gca().spines['top'].set_visible(False)\nplt.gca().spines['right'].set_visible(False)\nplt.grid(axis='x', linestyle='--', alpha=0.3)\n\n# 7. Show and Save as a high-quality image\nplt.tight_layout()\nplt.show()\nplt.savefig('weather_impact_analysis.png', dpi=300)",
      "outputs": [],
      "execution_count": null
    }
  ]
}