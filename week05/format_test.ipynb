{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "# Week 5 - Testing Structured Data File Formats\n\nThe goal of this project is to evaluate tradeoffs between different file formats for structured data. In particular, we're going to evaluate size vs time to write rows into CSV, compressed CSV, and Parquet formats.",
      "id": "ab5e5588-1eea-47bd-b5a9-cb54eb616ceb"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "# pyarrow is the library that provides support for parquet files\n# !pip install pyarrow",
      "id": "fe1515a8-f99a-4db1-b044-0cfaef5d0142"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "import sys\nimport os\nimport pyarrow\nimport pandas as pd\nimport numpy as np",
      "id": "83d9e881-025b-4062-bb39-40676daea0fc"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "# For my example, I'm going to generate some random data about locations on a theoretical map\n# Don't try to make sense out of the topology or geography\n\ndef create_data(NUMROWS:int):\n    raw = {\n        'lat': np.random.randint(0,180000, NUMROWS)/1000,  # 0.000-180.000\n        'lat_d': np.random.choice(['N','S'], NUMROWS),     # N or S\n        'lng': np.random.randint(0,180000, NUMROWS)/1000,  # 0.000-180.000\n        'lng_d': np.random.choice(['E','W'], NUMROWS),     # E or W\n        'elevation': np.random.randint(0,10000, NUMROWS),  # 0-10km\n        'climate': np.random.choice(['Tundra','Arid','Polar','Tropical','Alpine','Oceanic'], NUMROWS)\n    }\n\n    locations = pd.DataFrame(raw)\n    return locations",
      "id": "1c7f117f-f194-4da7-b079-3770f6a2ff6b"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "# We also need a function that can run our whole exercise and return the file size and timing\n# Returns (filesize, average_time)\ndef write_data(data:pd.DataFrame, format:str):\n    if format == 'csv':\n        writer = data.to_csv\n        filename = 'tmp.csv'\n    elif format == 'csv.gz':\n        writer = data.to_csv\n        filename = 'tmp.csv.gz'\n    elif format == 'parquet':\n        writer = data.to_parquet\n        filename = 'tmp.parquet'\n    else:\n        return (-1, -1)\n    \n    tm = %timeit -q -n1 -r10 -o writer(filename)\n\n    sz = os.stat(filename).st_size\n\n    return (sz, tm.average)",
      "id": "743a0432-1360-4033-9512-03080df63076"
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "# Here's our looped test\nsizes = [1e2, 5e2, 1e3, 5e3, 1e4, 3e4, 5e4, 7e4, 1e5, 1e6, 1e7, 1e8]\nformats = ['csv','csv.gz','parquet']\ntimings = []\n\nfor s in sizes:\n    data = create_data(int(s))\n    for f in formats:\n        print(f'Writing {s} rows to {f}')\n        (sz, tm) = write_data(data, f)\n        timings.append((int(s), f, sz,tm))",
      "id": "584b78e0-fd03-422c-a6bd-5c7c6059aea8"
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "# Plot size and time by format to see which format gives us the best size/time tradeoffs\n# We want something that doesn't go too far to the right (small) and stays low (fast) as the number of rows scales up\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndf = pd.DataFrame(timings, columns=['Rows','Format','Size','Time'])\nsns.lmplot(df, x='Size', y='Time', hue='Format')",
      "id": "1deb607c-8903-4739-8b50-52c02a348374"
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "# Let's plot the log of Time and Size to scale the axes\ndf['logSize'] = df['Size'].apply(np.log)\ndf['logTime'] = df['Time'].apply(np.log)\nsns.lmplot(df, x='logSize', y='logTime', hue='Format')",
      "id": "7ee5b2f5-7460-43d1-895c-c72940f36da1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "",
      "id": "cafb9f7f-78a5-4c2a-82c2-53a5d8bdd0d2"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "data5035",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}